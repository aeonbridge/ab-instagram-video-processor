{
  "title": "Ollama Tools",
  "content": "Source: https://docs.agno.com/reference/models/ollama-tools\n\nThe Ollama Tools model provides access to the Ollama models and passes tools in XML format to the model.\n\n| Parameter               | Type                          | Default                    | Description                                                      |\n| ----------------------- | ----------------------------- | -------------------------- | ---------------------------------------------------------------- |\n| `id`                    | `str`                         | `\"llama3.2\"`               | The name of the Ollama model to use                              |\n| `name`                  | `str`                         | `\"OllamaTools\"`            | The name of the model                                            |\n| `provider`              | `str`                         | `\"Ollama\"`                 | The provider of the model                                        |\n| `host`                  | `str`                         | `\"http://localhost:11434\"` | The host URL for the Ollama server                               |\n| `timeout`               | `Optional[int]`               | `None`                     | Request timeout in seconds                                       |\n| `format`                | `Optional[str]`               | `None`                     | The format to return the response in (e.g., \"json\")              |\n| `options`               | `Optional[Dict[str, Any]]`    | `None`                     | Additional model options (temperature, top\\_p, etc.)             |\n| `keep_alive`            | `Optional[Union[float, str]]` | `None`                     | How long to keep the model loaded (e.g., \"5m\", 3600 seconds)     |\n| `template`              | `Optional[str]`               | `None`                     | The prompt template to use                                       |\n| `system`                | `Optional[str]`               | `None`                     | System message to use                                            |\n| `raw`                   | `Optional[bool]`              | `None`                     | Whether to return raw response without formatting                |\n| `stream`                | `bool`                        | `True`                     | Whether to stream the response                                   |\n| `retries`               | `int`                         | `0`                        | Number of retries to attempt before raising a ModelProviderError |\n| `delay_between_retries` | `int`                         | `1`                        | Delay between retries, in seconds                                |\n| `exponential_backoff`   | `bool`                        | `False`                    | If True, the delay between retries is doubled each time          |\n\nThis model passes tools in XML format instead of JSON for better compatibility with certain models.",
  "code_samples": [],
  "headings": [
    {
      "level": "h2",
      "text": "Parameters",
      "id": "parameters"
    }
  ],
  "url": "llms-txt#ollama-tools",
  "links": []
}