{
  "title": "Crawl4AI",
  "content": "Source: https://docs.agno.com/integrations/toolkits/web-scrape/crawl4ai\n\n**Crawl4aiTools** enable an Agent to perform web crawling and scraping tasks using the Crawl4ai library.\n\nThe following example requires the `crawl4ai` library.\n\nThe following agent will scrape the content from the [https://github.com/agno-agi/agno](https://github.com/agno-agi/agno) webpage:\n\n| Parameter           | Type    | Default              | Description                                                                               |\n| ------------------- | ------- | -------------------- | ----------------------------------------------------------------------------------------- |\n| `max_length`        | `int`   | `1000`               | Specifies the maximum length of the text from the webpage to be returned.                 |\n| `timeout`           | `int`   | `60`                 | Timeout in seconds for web crawling operations.                                           |\n| `use_pruning`       | `bool`  | `False`              | Enable content pruning to remove less relevant content.                                   |\n| `pruning_threshold` | `float` | `0.48`               | Threshold for content pruning relevance scoring.                                          |\n| `bm25_threshold`    | `float` | `1.0`                | BM25 scoring threshold for content relevance.                                             |\n| `headless`          | `bool`  | `True`               | Run browser in headless mode.                                                             |\n| `wait_until`        | `str`   | `\"domcontentloaded\"` | Browser wait condition before crawling (e.g., \"domcontentloaded\", \"load\", \"networkidle\"). |\n| `enable_crawl`      | `bool`  | `True`               | Enable the web crawling functionality.                                                    |\n| `all`               | `bool`  | `False`              | Enable all available functions. When True, all enable flags are ignored.                  |\n\n| Function      | Description                                                                                                                                                                                                      |\n| ------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `web_crawler` | Crawls a website using crawl4ai's WebCrawler. Parameters include 'url' for the URL to crawl and an optional 'max\\_length' to limit the length of extracted content. The default value for 'max\\_length' is 1000. |\n\n## Developer Resources\n\n* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/crawl4ai.py)\n* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/crawl4ai_tools.py)",
  "code_samples": [
    {
      "code": "## Example\n\nThe following agent will scrape the content from the [https://github.com/agno-agi/agno](https://github.com/agno-agi/agno) webpage:",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Prerequisites",
      "id": "prerequisites"
    },
    {
      "level": "h2",
      "text": "Example",
      "id": "example"
    },
    {
      "level": "h2",
      "text": "Toolkit Params",
      "id": "toolkit-params"
    },
    {
      "level": "h2",
      "text": "Toolkit Functions",
      "id": "toolkit-functions"
    },
    {
      "level": "h2",
      "text": "Developer Resources",
      "id": "developer-resources"
    }
  ],
  "url": "llms-txt#crawl4ai",
  "links": []
}