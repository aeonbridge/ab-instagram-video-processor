{
  "title": "Enable all ScrapeGraph functions",
  "content": "scrapegraph_all = Agent(\n    tools=[\n        ScrapeGraphTools(all=True, render_heavy_js=True)\n    ],  # render_heavy_js=True scrapes all JavaScript\n    model=agent_model,\n    markdown=True,\n    stream=True,\n)\n\nscrapegraph_all.print_response(\"\"\"\nUse any appropriate scraping method to extract comprehensive information from https://www.wired.com/category/science/:\n- News articles and headlines\n- Convert to markdown if needed  \n- Search for specific information\n\"\"\")\n```\n\n<Note>View the [Startup Analyst example](/examples/use-cases/agents/startup-analyst-agent) </Note>\n\n| Parameter                | Type            | Default | Description                                                                                        |\n| ------------------------ | --------------- | ------- | -------------------------------------------------------------------------------------------------- |\n| `api_key`                | `Optional[str]` | `None`  | ScrapeGraph API key. If not provided, uses SGAI\\_API\\_KEY environment variable.                    |\n| `enable_smartscraper`    | `bool`          | `True`  | Enable the smartscraper function for LLM-powered data extraction.                                  |\n| `enable_markdownify`     | `bool`          | `False` | Enable the markdownify function for webpage to markdown conversion.                                |\n| `enable_crawl`           | `bool`          | `False` | Enable the crawl function for website crawling and data extraction.                                |\n| `enable_searchscraper`   | `bool`          | `False` | Enable the searchscraper function for web search and information extraction.                       |\n| `enable_agentic_crawler` | `bool`          | `False` | Enable the agentic\\_crawler function for automated browser actions and AI extraction.              |\n| `enable_scrape`          | `bool`          | `False` | Enable the scrape function for retrieving raw HTML content from websites.                          |\n| `render_heavy_js`        | `bool`          | `False` | Enable heavy JavaScript rendering for all scraping functions. Useful for SPAs and dynamic content. |\n| `all`                    | `bool`          | `False` | Enable all available functions. When True, all enable flags are ignored.                           |\n\n| Function          | Description                                                                                                                                                                                                            |\n| ----------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `smartscraper`    | Extract structured data from a webpage using LLM and natural language prompt. Parameters: url (str), prompt (str).                                                                                                     |\n| `markdownify`     | Convert a webpage to markdown format. Parameters: url (str).                                                                                                                                                           |\n| `crawl`           | Crawl a website and extract structured data. Parameters: url (str), prompt (str), data\\_schema (dict), cache\\_website (bool), depth (int), max\\_pages (int), same\\_domain\\_only (bool), batch\\_size (int).             |\n| `searchscraper`   | Search the web and extract information. Parameters: user\\_prompt (str).                                                                                                                                                |\n| `agentic_crawler` | Perform automated browser actions with optional AI extraction. Parameters: url (str), steps (List\\[str]), use\\_session (bool), user\\_prompt (Optional\\[str]), output\\_schema (Optional\\[dict]), ai\\_extraction (bool). |\n| `scrape`          | Get raw HTML content from a website. Useful for complete source code retrieval and custom processing. Parameters: website\\_url (str), headers (Optional\\[dict]).                                                       |\n\n## Developer Resources\n\n* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/scrapegraph.py)\n* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/scrapegraph_tools.py)\n* View [Tests](https://github.com/agno-agi/agno/blob/main/libs/agno/tests/unit/tools/test_scrapegraph.py)",
  "code_samples": [],
  "headings": [
    {
      "level": "h2",
      "text": "Toolkit Params",
      "id": "toolkit-params"
    },
    {
      "level": "h2",
      "text": "Toolkit Functions",
      "id": "toolkit-functions"
    },
    {
      "level": "h2",
      "text": "Developer Resources",
      "id": "developer-resources"
    }
  ],
  "url": "llms-txt#enable-all-scrapegraph-functions",
  "links": []
}