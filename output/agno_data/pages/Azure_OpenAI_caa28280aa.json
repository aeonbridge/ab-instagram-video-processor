{
  "title": "Azure OpenAI",
  "content": "Source: https://docs.agno.com/reference/models/azure-open-ai\n\nThe AzureOpenAI model provides access to Azure-hosted OpenAI models.\n\n| Parameter                 | Type                              | Default                | Description                                                                        |\n| ------------------------- | --------------------------------- | ---------------------- | ---------------------------------------------------------------------------------- |\n| `id`                      | `str`                             | `\"gpt-4o\"`             | The id of the Azure OpenAI model to use                                            |\n| `name`                    | `str`                             | `\"AzureOpenAI\"`        | The name of the model                                                              |\n| `provider`                | `str`                             | `\"Azure\"`              | The provider of the model                                                          |\n| `temperature`             | `Optional[float]`                 | `None`                 | Controls randomness in the model's output (0.0 to 2.0)                             |\n| `max_tokens`              | `Optional[int]`                   | `None`                 | Maximum number of tokens to generate in the response                               |\n| `max_completion_tokens`   | `Optional[int]`                   | `None`                 | Maximum number of completion tokens to generate                                    |\n| `frequency_penalty`       | `Optional[float]`                 | `None`                 | Penalizes new tokens based on their frequency in the text so far (-2.0 to 2.0)     |\n| `presence_penalty`        | `Optional[float]`                 | `None`                 | Penalizes new tokens based on whether they appear in the text so far (-2.0 to 2.0) |\n| `top_p`                   | `Optional[float]`                 | `None`                 | Controls diversity via nucleus sampling (0.0 to 1.0)                               |\n| `stop`                    | `Optional[Union[str, List[str]]]` | `None`                 | Up to 4 sequences where the API will stop generating further tokens                |\n| `seed`                    | `Optional[int]`                   | `None`                 | Random seed for deterministic sampling                                             |\n| `logprobs`                | `Optional[bool]`                  | `None`                 | Whether to return log probabilities of the output tokens                           |\n| `top_logprobs`            | `Optional[int]`                   | `None`                 | Number of most likely tokens to return log probabilities for (0 to 20)             |\n| `user`                    | `Optional[str]`                   | `None`                 | A unique identifier representing your end-user                                     |\n| `request_params`          | `Optional[Dict[str, Any]]`        | `None`                 | Additional parameters to include in the request                                    |\n| `azure_endpoint`          | `Optional[str]`                   | `None`                 | The Azure endpoint URL (defaults to AZURE\\_OPENAI\\_ENDPOINT env var)               |\n| `api_key`                 | `Optional[str]`                   | `None`                 | The API key for Azure OpenAI (defaults to AZURE\\_OPENAI\\_API\\_KEY env var)         |\n| `api_version`             | `str`                             | `\"2024-12-01-preview\"` | The API version to use                                                             |\n| `azure_ad_token`          | `Optional[str]`                   | `None`                 | Azure AD token for authentication                                                  |\n| `azure_ad_token_provider` | `Optional[Any]`                   | `None`                 | Azure AD token provider for authentication                                         |\n| `timeout`                 | `Optional[float]`                 | `None`                 | Request timeout in seconds                                                         |\n| `max_retries`             | `Optional[int]`                   | `None`                 | Maximum number of retries for failed requests                                      |\n| `client_params`           | `Optional[Dict[str, Any]]`        | `None`                 | Additional parameters for client configuration                                     |\n| `retries`                 | `int`                             | `0`                    | Number of retries to attempt before raising a ModelProviderError                   |\n| `delay_between_retries`   | `int`                             | `1`                    | Delay between retries, in seconds                                                  |\n| `exponential_backoff`     | `bool`                            | `False`                | If True, the delay between retries is doubled each time                            |",
  "code_samples": [],
  "headings": [
    {
      "level": "h2",
      "text": "Parameters",
      "id": "parameters"
    }
  ],
  "url": "llms-txt#azure-openai",
  "links": []
}