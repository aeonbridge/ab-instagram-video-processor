{
  "title": "-*- Print a response to the cli",
  "content": "asyncio.run(agent.aprint_response(\"Share a breakfast recipe.\", markdown=True))\n\nbash  theme={null}\n    ollama pull llama3.1:8b\n    bash  theme={null}\n    pip install -U ollama agno\n    bash Mac theme={null}\n      python cookbook/models/ollama/async_basic.py\n      bash Windows theme={null}\n      python cookbook/models/ollama/async_basic.py\n      ```\n    </CodeGroup>\n  </Step>\n</Steps>",
  "code_samples": [
    {
      "code": "## Usage\n\n<Steps>\n  <Snippet file=\"create-venv-step.mdx\" />\n\n  <Step title=\"Install Ollama\">\n    Follow the [Ollama installation guide](https://github.com/ollama/ollama?tab=readme-ov-file#macos) and run:",
      "language": "unknown"
    },
    {
      "code": "</Step>\n\n  <Step title=\"Install libraries\">",
      "language": "unknown"
    },
    {
      "code": "</Step>\n\n  <Step title=\"Run Agent\">\n    <CodeGroup>",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Usage",
      "id": "usage"
    }
  ],
  "url": "llms-txt#-*--print-a-response-to-the-cli",
  "links": []
}