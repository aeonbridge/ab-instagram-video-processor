{
  "title": "HuggingFace",
  "content": "Source: https://docs.agno.com/reference/models/huggingface\n\nThe HuggingFace model provides access to models hosted on the HuggingFace Hub.\n\n| Parameter               | Type              | Default                                         | Description                                                      |\n| ----------------------- | ----------------- | ----------------------------------------------- | ---------------------------------------------------------------- |\n| `id`                    | `str`             | `\"microsoft/DialoGPT-medium\"`                   | The id of the Hugging Face model to use                          |\n| `name`                  | `str`             | `\"HuggingFace\"`                                 | The name of the model                                            |\n| `provider`              | `str`             | `\"HuggingFace\"`                                 | The provider of the model                                        |\n| `api_key`               | `Optional[str]`   | `None`                                          | The API key for Hugging Face (defaults to HF\\_TOKEN env var)     |\n| `base_url`              | `str`             | `\"https://api-inference.huggingface.co/models\"` | The base URL for Hugging Face Inference API                      |\n| `wait_for_model`        | `bool`            | `True`                                          | Whether to wait for the model to load if it's cold               |\n| `use_cache`             | `bool`            | `True`                                          | Whether to use caching for faster inference                      |\n| `max_tokens`            | `Optional[int]`   | `None`                                          | Maximum number of tokens to generate                             |\n| `temperature`           | `Optional[float]` | `None`                                          | Controls randomness in the model's output                        |\n| `top_p`                 | `Optional[float]` | `None`                                          | Controls diversity via nucleus sampling                          |\n| `repetition_penalty`    | `Optional[float]` | `None`                                          | Penalty for repeating tokens (higher values reduce repetition)   |\n| `retries`               | `int`             | `0`                                             | Number of retries to attempt before raising a ModelProviderError |\n| `delay_between_retries` | `int`             | `1`                                             | Delay between retries, in seconds                                |\n| `exponential_backoff`   | `bool`            | `False`                                         | If True, the delay between retries is doubled each time          |",
  "code_samples": [],
  "headings": [
    {
      "level": "h2",
      "text": "Parameters",
      "id": "parameters"
    }
  ],
  "url": "llms-txt#huggingface",
  "links": []
}