{
  "title": "Provide the agent with the audio file and get result as text",
  "content": "agent = Agent(\n    model=OpenAIChat(id=\"gpt-5-mini-audio-preview\", modalities=[\"text\"]),\n    markdown=True,\n)\nagent.print_response(\n    \"What is in this audio?\", audio=[Audio(content=wav_data, format=\"wav\")]\n)\nbash  theme={null}\n    export OPENAI_API_KEY=xxx\n    bash  theme={null}\n    pip install -U openai requests agno\n    bash Mac theme={null}\n      python cookbook/models/openai/chat/audio_input_agent.py\n      bash Windows theme={null}\n      python cookbook/models/openai/chat/audio_input_agent.py\n      ```\n    </CodeGroup>\n  </Step>\n</Steps>",
  "code_samples": [
    {
      "code": "## Usage\n\n<Steps>\n  <Snippet file=\"create-venv-step.mdx\" />\n\n  <Step title=\"Set your API key\">",
      "language": "unknown"
    },
    {
      "code": "</Step>\n\n  <Step title=\"Install libraries\">",
      "language": "unknown"
    },
    {
      "code": "</Step>\n\n  <Step title=\"Run Agent\">\n    <CodeGroup>",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Usage",
      "id": "usage"
    }
  ],
  "url": "llms-txt#provide-the-agent-with-the-audio-file-and-get-result-as-text",
  "links": []
}