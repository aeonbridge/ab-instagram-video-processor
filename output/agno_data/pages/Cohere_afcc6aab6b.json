{
  "title": "Cohere",
  "content": "Source: https://docs.agno.com/reference/models/cohere\n\nThe Cohere model provides access to Cohere's language models.\n\n| Parameter               | Type                       | Default                    | Description                                                      |\n| ----------------------- | -------------------------- | -------------------------- | ---------------------------------------------------------------- |\n| `id`                    | `str`                      | `\"command-r-plus-08-2024\"` | The id of the Cohere model to use                                |\n| `name`                  | `str`                      | `\"CohereChat\"`             | The name of the model                                            |\n| `provider`              | `str`                      | `\"Cohere\"`                 | The provider of the model                                        |\n| `api_key`               | `Optional[str]`            | `None`                     | The API key for Cohere (defaults to COHERE\\_API\\_KEY env var)    |\n| `max_tokens`            | `Optional[int]`            | `None`                     | Maximum number of tokens to generate                             |\n| `temperature`           | `Optional[float]`          | `None`                     | Controls randomness in the model's output (0.0 to 1.0)           |\n| `p`                     | `Optional[float]`          | `None`                     | Controls diversity via nucleus sampling (0.0 to 1.0)             |\n| `k`                     | `Optional[int]`            | `None`                     | Controls diversity via top-k sampling                            |\n| `seed`                  | `Optional[int]`            | `None`                     | Random seed for deterministic sampling                           |\n| `frequency_penalty`     | `Optional[float]`          | `None`                     | Reduces repetition by penalizing frequent tokens (0.0 to 1.0)    |\n| `presence_penalty`      | `Optional[float]`          | `None`                     | Reduces repetition by penalizing present tokens (0.0 to 1.0)     |\n| `stop_sequences`        | `Optional[List[str]]`      | `None`                     | List of strings that stop generation                             |\n| `response_format`       | `Optional[Dict[str, Any]]` | `None`                     | Specifies the format of the response (e.g., JSON)                |\n| `citation_options`      | `Optional[Dict[str, Any]]` | `None`                     | Options for citation generation                                  |\n| `request_params`        | `Optional[Dict[str, Any]]` | `None`                     | Additional parameters to include in the request                  |\n| `client_params`         | `Optional[Dict[str, Any]]` | `None`                     | Additional parameters for client configuration                   |\n| `retries`               | `int`                      | `0`                        | Number of retries to attempt before raising a ModelProviderError |\n| `delay_between_retries` | `int`                      | `1`                        | Delay between retries, in seconds                                |\n| `exponential_backoff`   | `bool`                     | `False`                    | If True, the delay between retries is doubled each time          |",
  "code_samples": [],
  "headings": [
    {
      "level": "h2",
      "text": "Parameters",
      "id": "parameters"
    }
  ],
  "url": "llms-txt#cohere",
  "links": []
}