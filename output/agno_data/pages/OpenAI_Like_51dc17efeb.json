{
  "title": "OpenAI Like",
  "content": "Source: https://docs.agno.com/reference/models/openai-like\n\nThe OpenAI Like model works as a wrapper for the OpenAILike models.\n\n| Parameter                            | Type                              | Default                       | Description                                                           |\n| ------------------------------------ | --------------------------------- | ----------------------------- | --------------------------------------------------------------------- |\n| `id`                                 | `str`                             | `\"gpt-4o\"`                    | The id of the model to use                                            |\n| `name`                               | `str`                             | `\"OpenAILike\"`                | The name of the model                                                 |\n| `provider`                           | `str`                             | `\"OpenAILike\"`                | The provider of the model                                             |\n| `api_key`                            | `Optional[str]`                   | `None`                        | The API key for authentication (defaults to OPENAI\\_API\\_KEY env var) |\n| `base_url`                           | `str`                             | `\"https://api.openai.com/v1\"` | The base URL for the API                                              |\n| `supports_native_structured_outputs` | `Optional[bool]`                  | `None`                        | Whether the model supports native structured outputs                  |\n| `response_format`                    | `Optional[str]`                   | `None`                        | The format of the response                                            |\n| `seed`                               | `Optional[int]`                   | `None`                        | Random seed for deterministic sampling                                |\n| `stop`                               | `Optional[Union[str, List[str]]]` | `None`                        | Up to 4 sequences where the API will stop generating further tokens   |\n| `stream`                             | `bool`                            | `True`                        | Whether to stream the response                                        |\n| `temperature`                        | `Optional[float]`                 | `None`                        | Controls randomness in the model's output                             |\n| `top_p`                              | `Optional[float]`                 | `None`                        | Controls diversity via nucleus sampling                               |\n| `request_params`                     | `Optional[Dict[str, Any]]`        | `None`                        | Additional parameters to include in the request                       |\n| `client_params`                      | `Optional[Dict[str, Any]]`        | `None`                        | Additional parameters for client configuration                        |\n| `retries`                            | `int`                             | `0`                           | Number of retries to attempt before raising a ModelProviderError      |\n| `delay_between_retries`              | `int`                             | `1`                           | Delay between retries, in seconds                                     |\n| `exponential_backoff`                | `bool`                            | `False`                       | If True, the delay between retries is doubled each time               |",
  "code_samples": [],
  "headings": [
    {
      "level": "h2",
      "text": "Parameters",
      "id": "parameters"
    }
  ],
  "url": "llms-txt#openai-like",
  "links": []
}